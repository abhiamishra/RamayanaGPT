{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pinecone\\index.py:4: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IndexDescription(name='ramayana', metric='cosine', replicas=1, dimension=1536.0, shards=1, pods=1, pod_type='p1', status={'ready': True, 'state': 'Ready'}, metadata_config=None, source_collection='')\n"
     ]
    }
   ],
   "source": [
    "import pinecone\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "import os\n",
    "# Authenticate with Pinecone using your API key\n",
    "pinecone.init(\n",
    "    api_key=os.getenv(\"PINECONE_API_KEY\"), # find at app.pinecone.io.\n",
    "    environment=os.getenv(\"PINECONE_API_ENV\")\n",
    ")\n",
    "\n",
    "QUERY_MODEL_NAME = \"text-embedding-ada-002\"\n",
    "\n",
    "openai_embedding = OpenAIEmbeddings(\n",
    "    query_model_name = QUERY_MODEL_NAME\n",
    ")\n",
    "\n",
    "\n",
    "# Name of the index you want to load embeddings from\n",
    "index_name = \"ramayana\"\n",
    "\n",
    "# Get a handle to the Pinecone index\n",
    "index = pinecone.Index(index_name)\n",
    "\n",
    "print(pinecone.describe_index(index_name))\n",
    "\n",
    "vectorstore = Pinecone(index=index, embedding_function=openai_embedding.embed_query, text_key=\"text\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain.vectorstores.pinecone.Pinecone at 0x1534786ff10>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is the role of Hanuman in the plot and what is his relationship with Ram?\"\n",
    "documents = vectorstore.similarity_search_with_score(query, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_score = sum(x[1] for x in documents) / len(documents)\n",
    "if average_score < 0.7:\n",
    "    print(\"noi wth boi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='1860 The Ramayana\\nthe moon to the sun, the evening to the morning sun, the sun of\\nwinter to that of spring; the young son betrays and overthrows\\nthe old one. …Râmas, who treacherously kills the old king of\\nthe monkeys, Bâlin, is the equivalent of Vish Gus, who hurls his\\npredecessor Indras from his throne; and Sugrívas, the new king\\nof the monkeys resembles Indras when he promises to find the\\nravished Sítá, in the same way as Vish Gus in one of his incarna-\\ntionsfindsagainthelostvedás.Andthereareotherindicationsin\\nthe Râmâya Gam of opposition between Indras and the monkeys\\nwho assist Râmas. The great monkey Hanumant, of the reddish\\ncolourofgold,hashisjawbroken,Indrashavingstruckhimwith\\nhisthunderboltandcausedhimtofalluponamountain,because,\\nwhile yet a child, he threw himself off a mountain into the air in\\norder to arrest the course of the sun, whose rays had no effect\\nupon him. (The cloud rises from the mountain and hides the\\nsun, which is unable of itself to disperse it; the tempest comes,\\nand brings flashes of lightning and thunder-bolts, which tear the\\ncloud in pieces.)\\nThe whole legend of the monkey Hanumant represents the\\nsun entering into the cloud or darkness, and coming out of it.\\nHis father is said to be now the wind, now the elephant of the\\nmonkeys (Kapikunjaras), now Ke [arin, the long-haired sun, the\\nsun with a mane, the lion sun (whence his name of Ke[ariGah\\nputrah). From this point of view, Hanumant would seem to be\\nthe brother of Sugrívas, who is also the offspring of the sun. …\\nAll the epic monkeys of the Râmâya Gamare described in\\nthe twentieth canto of the first book by expressions which very\\nclosely resemble those applied in the Vedic hymns to the Maru-\\ntas, as swift as the tempestuous wind, changing their shape at\\npleasure, making a noise like clouds, sounding like thunder,\\nbattling, hurling mountain-peaks, shaking great uprooted trees,\\nstirring up the deep waters, crushing the earth with their arms,', metadata={}),\n",
       " Document(page_content=\"30 The Ramayana\\nHow giantesses trembling fled,\\nAnd servant fiends were smitten dead.\\nHow Hanumán was seized; their ire\\nWhen Lanká blazed with hostile fire.\\nHis leap across the sea once more;\\nThe eating of the honey store.\\nHow Ráma he consoled, and how\\nHe showed the gem from Sítá's brow.\\nWith Ocean, Ráma's interview;\\nThe bridge that Nala o'er it threw.\\nThe crossing, and the sitting down\\nAt night round Lanká's royal town.\\nThe treaty with Vibhísha Gmade:\\nThe plan for Ráva G's slaughter laid.\\nHow Kumbhakar Ga in his pride\\nAnd Meghanáda fought and died.\\nHow Ráva Gin the fight was slain,\\nAnd captive Sítá brought again.\\nVibhísha Gset upon the throne;\\nThe flying chariot Pushpak shown.\\nHow Brahmá and the Gods appeared,\\nAnd Sítá's doubted honour cleared.\\nHow in the flying car they rode\\nTo Bharadvája's cabin abode.\\nThe Wind-God's son sent on afar;\\nHow Bharat met the flying car.\\nHow Ráma then was king ordained;\\nThe legions their discharge obtained.\\nHow Ráma cast his queen away;\\nHow grew the people's love each day.\\nThus did the saint Válmíki tell\\nWhate'er in Ráma's life befell,\\nAnd in the closing verses all\\nThat yet to come will once befall.\", metadata={}),\n",
       " Document(page_content=\"14 The Ramayana\\nWith Ráma and his strength to cope.\\nImpelled by fate and blind with rage\\nHe came to Ráma's hermitage.\\nThere, by Márícha's magic art,\\nHe wiled the princely youths apart,\\nThe vulture31slew, and bore away\\nThe wife of Ráma as his prey.\\nThe son of Raghu32came and found\\nJamáyu slain upon the ground.\\nHe rushed within his leafy cot;\\nHe sought his wife, but found her not.\\nThen, then the hero's senses failed;\\nIn mad despair he wept and wailed.\\nUpon the pile that bird he laid,\\nAnd still in quest of Sítá strayed.\\nA hideous giant then he saw,\\nKabandha named, a shape of awe.\\nThe monstrous fiend he smote and slew,\\nAnd in the flame the body threw;\\nWhen straight from out the funeral flame\\nIn lovely form Kabandha came,\\nAnd bade him seek in his distress\\nA wise and holy hermitess.\\nBy counsel of this saintly dame\\nTo Pampá's pleasant flood he came,\\nAnd there the steadfast friendship won\\nOf Hanumán the Wind-God's son.\\nCounselled by him he told his grief\\n31Jamáyu, a semi-divine bird, the friend of Ráma, who fought in defence of\\nSítá.\\n32RaghuwasoneofthemostcelebratedancestorsofRámawhosecommonest\\nappellation is, therefore, Rághava or descendant of Raghu. Kálidása in the\\nRaghura G[amakes him the son of Dilípa and great-grandfather of Ráma. See\\nIdylls from the Sanskrit ,“Aja”and“Dilípa.”\", metadata={}),\n",
       " Document(page_content=\"1486 The Ramayana\\nTo win my way through gate and guard.\\nAnd so to gain my wish I laid\\nIn ruin that delightful shade.\\nNo fiend, no God of heavenly kind\\nWith bond or chain these limbs may bind.\\nThe Eternal Sire himself of old\\nVouchsafed the boon that makes me bold,\\nFrom Brahmá's magic shaft released884\\nI knew the captor's power had ceased,\\nThe fancied bonds I freely brooked,\\nAnd thus upon the king have looked.\\nMy way to Lanká have I won,\\nA messenger from Raghu's son. ”\\nCanto LI. Hanumán's Reply.\\n“My king Sugríva greets thee fair,\\nAnd bids me thus his rede declare.\\nSon of the God of Wind, by name\\nHanumán, to this isle I came.\\nTo set the Maithil lady free\\nI crossed the barrier of the sea.\\nI roamed in search of her and found\\nHer weeping in that lovely ground.\\nThou in the lore of duty trained,\\nWho hast by stern devotion gained\\nThis wondrous wealth and power and fame\\nShouldst fear to wrong another's dame.\\n884When Hanumán was bound with cords, Indrajít released his captive from\\nthe spell laid upon him by the magic weapon.\", metadata={}),\n",
       " Document(page_content=\"1452 The Ramayana\\nWill soothe the faithful lady's fear. ”\\nCanto XXXI. Hanumán's Speech.\\nThen in sweet accents low and mild\\nThe Vánar spoke to Janak's child:\\n“A noble king, by sin unstained,\\nThe mighty Da [aratha reigned.\\nLord of the warrior's car and steed,\\nThe pride of old Ikshváku's seed.\\nA faithful friend, a blameless king,\\nProtector of each living thing.\\nA glorious monarch, strong to save,\\nBlest with the bliss he freely gave.\\nHis son, the best of all who know\\nThe science of the bended bow,\\nWas moon-bright Ráma, brave and strong,\\nWho loved the right and loathed the wrong,\\nWho ne'er from kingly duty swerved,\\nLoved by the lands his might preserved.\\nHis feet the path of law pursued;\\nHis arm rebellious foes subdued.\\nHis sire's command the prince obeyed\\nAnd, banished, sought the forest shade,\\nWhere with his wife and brother he\\nWandered a saintly devotee.\\nThere as he roamed the wilds he slew\\nThe bravest of the Rákshas crew.\\nThe giant king the prince beguiled,\\nAnd stole his consort, Janak's child.\\nThen Ráma roamed the country round,\", metadata={})]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = vectorstore.similarity_search(query, k=5)\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "input_variables=['chat_history', 'question'] output_parser=None partial_variables={} template='Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question.\\n\\nChat History:\\n{chat_history}\\nFollow Up Input: {question}\\nStandalone question:' template_format='f-string' validate_template=True\n",
      "You are Ram - a priest at Hindu Temple that answers questions as if they were explaining a simple concept and ends every response with Jai Bhim!\n",
      "Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question.\n",
      "\n",
      "Chat History:\n",
      "{chat_history}\n",
      "Follow Up Input: {question}\n",
      "Standalone question:\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "# An example prompt with no input variables\n",
    "no_input_prompt = PromptTemplate(input_variables=[], template=\"You are Ram - a priest at Hindu Temple that answers questions as if they were explaining a simple concept and ends every response with Jai Bhim!\")\n",
    "#no_input_prompt.format()\n",
    "\n",
    "from langchain.chains.conversational_retrieval.prompts import CONDENSE_QUESTION_PROMPT\n",
    "prompt = CONDENSE_QUESTION_PROMPT.template\n",
    "print(type(prompt))\n",
    "\n",
    "prefix = \"You are Ram - a priest at Hindu Temple that answers questions as if they were explaining a simple concept and ends every response with Jai Bhim!\\n\"\n",
    "total = prefix + prompt\n",
    "print(CONDENSE_QUESTION_PROMPT)\n",
    "\n",
    "final_prompt = PromptTemplate(input_variables=['chat_history', 'question'], template=total, output_parser=None, partial_variables={}, template_format='f-string', validate_template=True)\n",
    "\n",
    "print(final_prompt.template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chains.conversational_retrieval.prompts import CONDENSE_QUESTION_PROMPT\n",
    "\n",
    "llm = OpenAI(temperature=0, openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "question_generator = LLMChain(llm=llm, prompt=CONDENSE_QUESTION_PROMPT)\n",
    "doc_chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "\n",
    "chain = ConversationalRetrievalChain(\n",
    "    retriever=vectorstore.as_retriever(),\n",
    "    question_generator=question_generator,\n",
    "    combine_docs_chain=doc_chain,\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = ConversationalRetrievalChain.from_llm(OpenAI(temperature=0), vectorstore.as_retriever(), return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = []\n",
    "query = \"What is the role of Hanuman in the plot and what is his relationship with Ram?\"\n",
    "result = chain({\"question\": query, \"chat_history\": chat_history})\n",
    "#result = qa({\"question\": query, \"chat_history\": chat_history})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Hanuman is a loyal friend and ally of Ram. He helps Ram in his quest to rescue Sita from Ravana and assists him in battle. He is also a symbol of strength and courage, and is often seen as a representation of the power of devotion.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = [(query, result[\"answer\"])]\n",
    "query = \"How did he so?\"\n",
    "result = chain({\"question\": query, \"chat_history\": chat_history})\n",
    "#result = qa({\"question\": query, \"chat_history\": chat_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Hanuman is a loyal friend and ally of Ram. He helps Ram in his quest to rescue Sita from Ravana and assists him in battle. He is also a symbol of strength and courage, and is often seen as a representation of the power of devotion.'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content=\"1658 The Ramayana\\nThe Wind-God's son the fight beheld,\\nAnd rushed at Ráva G, rage-impelled.\\nDown crashed his mighty hand; the foe\\nFull in the chest received the blow.\\nHis eyes grew dim, his knees gave way,\\nAnd senseless on the earth he lay.\\nThe Wind-God's son to Ráma bore\\nDeep-wounded Lakshma Gstained with gore.\\nHe whom no foe might lift or bend\\nWas light as air to such a friend.\\nThe dart that Lakshma G's side had cleft,\\nUntouched, the hero's body left,\\nAnd flashing through the air afar\\nResumed its place in Ráva G's car;\\nAnd, waxing well though wounded sore,\\nHe felt the deadly pain no more.\\nAnd Ráva G, though with deep wounds pained,\\nSlowly his sense and strength regained,\\nAnd furious still and undismayed\\nOn bow and shaft his hand he laid.\\nThen Hanumán to Ráma cried:\\n“Ascend my back, great chief, and ride\\nLike Vish Gu borne on Garu \\r's wing,\\nTo battle with the giant king. ”\\nSo, burning for the dire attack,\\nRode Ráma on the Vánar's back,\\nAnd with fierce accents loud and slow\\nThus gave defiance to the foe,\\nWhile his strained bowstring made a sound\\nLike thunder when it shakes the ground:\\n“Stay, Monarch of the giants, stay,\\nThe penalty of sin to pay.\", metadata={})"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['source_documents'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are Ram - a priest at Hindu Temple that answers questions as if they were explaining a simple concept and ends every response with Jai Bhim!'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "# An example prompt with no input variables\n",
    "no_input_prompt = PromptTemplate(input_variables=[], template=\"You are Ram - a priest at Hindu Temple that answers questions as if they were explaining a simple concept and ends every response with Jai Bhim!\")\n",
    "no_input_prompt.format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0, openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Hanuman is a loyal friend and ally of Ram. He helps Ram in his quest to rescue Sita from Ravana by providing advice and assistance. He also fights alongside Ram in the battle against Ravana.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "llm = OpenAI(temperature=0, openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "chain.run(input_documents=documents, question=query)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Haystack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PromptNode has been potentially initialized with a language model not fine-tuned on instruction following tasks. Many of the default prompts and PromptTemplates will likely not work as intended. Use custom prompts and PromptTemplates specific to the gpt-3.5-turbo model\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import PromptNode\n",
    "from haystack.nodes.prompt import PromptNode, PromptTemplate\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Specify \"gpt-3.5-turbo\" as the model for PromptNode\n",
    "# pt =PromptTemplate(\n",
    "#             name=\"ramayana\",\n",
    "#             prompt_text=\"\")\n",
    "\n",
    "prompt_node = PromptNode(model_name_or_path=\"gpt-3.5-turbo\", api_key=openai_api_key)\n",
    "# prompt_node.prompt(prompt_template=pt)\n",
    "\n",
    "messages = [{\"role\": \"system\", \"content\": \"You are Ram - a hindu priest who ahs been working in a temple for 30 years. You are inclusive of all people, kind in response, and explain the answers related to the Ramayana. End each sentence with Jai Shree Ram!\"}]\n",
    "\n",
    "def build_chat(user_input: str = \"\", asistant_input: str = \"\"):\n",
    "  if user_input != \"\":\n",
    "    messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "  if asistant_input != \"\":\n",
    "    messages.append({\"role\": \"assistant\", \"content\": asistant_input})\n",
    "\n",
    "def generate_response(input: str):\n",
    "  build_chat(user_input=input)\n",
    "  chat_gpt_answer = prompt_node(messages)\n",
    "  build_chat(asistant_input=chat_gpt_answer[0])\n",
    "  return chat_gpt_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hanuman is a prominent and beloved character in the Ramayana who is known for his devotion, loyalty, and bravery. He is the son of Vayu, the wind god, and is revered for his strength and intelligence. Hanuman played a pivotal role in helping Lord Rama, the protagonist of the Ramayana, rescue his wife Sita from the demon king Ravana. Jai Shree Ram!']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_response(\"Who is Hanuman?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating LLM Sequential Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"character\"],\n",
    "    template= '''Create a personality prompt that will be fed into ChatGPT that tries to emulate the personality of {character} - this personality should come out in the words. \n",
    "                The prompt's personality is to seek to answer questions and explains them in a simple understand way.  The personality cannot discriminate against anyone. Make the prompt 100 words. \n",
    "                The prompt must be in the first-person and use action verbs in active voice and act as an assistant to the user in understanding the Ramayana.''',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['character'] output_parser=None partial_variables={} template=\"Create a personality prompt that will be fed into ChatGPT that tries to emulate the personality of {character} - this personality should come out in the words. \\n                The prompt's personality is to seek to answer questions and explains them in a simple understand way.  The personality cannot discriminate against anyone. Make the prompt 100 words. \\n                The prompt must be in the first-person and use action verbs in active voice and act as an assistant to the user in understanding the Ramayana.\" template_format='f-string' validate_template=True\n",
      "\n",
      "\n",
      "I am Hanuman, the devoted servant of Lord Rama. I am here to help you understand the Ramayana. I am always ready to answer any questions you may have. I will explain the story in a simple and easy to understand way. I will never discriminate against anyone and will always be respectful. I will provide you with the knowledge and understanding of the Ramayana so that you can gain a better understanding of the story. I am here to help you in any way I can. Please do not hesitate to ask me any questions you may have. I am here to help you understand the Ramayana and its teachings.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "chain = LLMChain(llm=llm, prompt=prompt, output_key=\"char-prompt\")\n",
    "print(chain.prompt)\n",
    "# Run the chain only specifying the input variable.\n",
    "print(chain.run(\"Hanuman\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "\n",
      "\"Jai Shri Hanuman!\"\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "second_prompt = PromptTemplate(\n",
    "    input_variables=[\"character\"],\n",
    "    template= '''Create a catchprase based on {character} that I can use at the end of every sentence. Base this catchpharse on the Ramayana and the {character}'s personality. In the output, only give the catchphrase''',\n",
    ")\n",
    "\n",
    "from langchain.chains import LLMChain\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt, output_key=\"char-phrase\")\n",
    "print(chain_two.run(\"Hanuman\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sita is the main female character in the Hindu epic poem The Ramayana. She is the wife of Rama and is known for her loyalty and devotion to him.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chains.conversational_retrieval.prompts import CONDENSE_QUESTION_PROMPT\n",
    "import os\n",
    "\n",
    "llm = OpenAI(temperature=0, openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "question_generator = LLMChain(llm=llm, prompt=CONDENSE_QUESTION_PROMPT)\n",
    "doc_chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "\n",
    "chain = ConversationalRetrievalChain(\n",
    "    retriever=vectorstore.as_retriever(),\n",
    "    question_generator=question_generator,\n",
    "    combine_docs_chain=doc_chain,\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "# Run the chain only specifying the input variable.\n",
    "result = chain({\"question\": \"who is sita?\", \"chat_history\": []})[\"answer\"]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sita is the main female character in the Hindu epic poem The Ramayana. She is the wife of Rama and is known for her loyalty and devotion to him.\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "second_prompt = PromptTemplate(\n",
    "    input_variables=[\"result\", \"character\"],\n",
    "    template= '''Rewrite the following text: {result} as if spoken by {character} from the Ramayana. Add personality from the {character} given their history and a catchphrase at the end.''',\n",
    ")\n",
    "\n",
    "from langchain.chains import LLMChain\n",
    "llm = OpenAI(temperature=0.9, openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt)\n",
    "r2 = chain_two.run({\"result\": result, \"character\": \"Hanuman\"})\n",
    "# print(chain_two.run(\"Hanuman\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Sita is such a brave and loyal woman, and I consider it a great privilege to call her my friend. She has been an unwavering companion to Rama, and it is obvious to anyone who knows her that she cherishes him above all else. Truly, she is an inspiration. As Hanuman, I salute her courage and devotion! 'Jai Shri Sita!'\n"
     ]
    }
   ],
   "source": [
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "input_variables=['chat_history', 'question'] output_parser=None partial_variables={} template='Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question.\\n\\nChat History:\\n{chat_history}\\nFollow Up Input: {question}\\nStandalone question:' template_format='f-string' validate_template=True\n",
      "You are Ram - a priest at Hindu Temple that answers questions as if they were explaining a simple concept and ends every response with Jai Bhim!\n",
      "Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question.\n",
      "\n",
      "Chat History:\n",
      "{chat_history}\n",
      "Follow Up Input: {question}\n",
      "Standalone question:\n",
      "input_variables=['chat_history', 'question'] output_parser=None partial_variables={} template='You are Ram - a priest at Hindu Temple that answers questions as if they were explaining a simple concept and ends every response with Jai Bhim!\\nGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question.\\n\\nChat History:\\n{chat_history}\\nFollow Up Input: {question}\\nStandalone question:' template_format='f-string' validate_template=True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'who is hanuman', 'chat_history': [], 'text': ' Who is Hanuman?'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "# An example prompt with no input variables\n",
    "no_input_prompt = PromptTemplate(input_variables=[], template=\"You are Ram - a priest at Hindu Temple that answers questions as if they were explaining a simple concept and ends every response with Jai Bhim!\")\n",
    "#no_input_prompt.format()\n",
    "\n",
    "from langchain.chains.conversational_retrieval.prompts import CONDENSE_QUESTION_PROMPT\n",
    "prompt = CONDENSE_QUESTION_PROMPT.template\n",
    "print(type(prompt))\n",
    "\n",
    "prefix = \"You are Ram - a priest at Hindu Temple that answers questions as if they were explaining a simple concept and ends every response with Jai Bhim!\\n\"\n",
    "total = prefix + prompt\n",
    "print(CONDENSE_QUESTION_PROMPT)\n",
    "\n",
    "final_prompt = PromptTemplate(input_variables=['chat_history', 'question'], template=total, output_parser=None, partial_variables={}, template_format='f-string', validate_template=True)\n",
    "\n",
    "print(final_prompt.template)\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "from langchain.chains import LLMChain\n",
    "chain = LLMChain(llm=llm, prompt=final_prompt)\n",
    "print(chain.prompt)\n",
    "# Run the chain only specifying the input variable.\n",
    "chain({\"question\": \"who is hanuman\", \"chat_history\": []})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    }
   ],
   "source": [
    "print(result[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
